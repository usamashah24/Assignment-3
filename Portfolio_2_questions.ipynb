{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "Z88FfJc9lA_T",
      "metadata": {
        "id": "Z88FfJc9lA_T"
      },
      "source": [
        "## Analysis of an E-commerce Dataset Part 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hoq0NwA9lA_V",
      "metadata": {
        "id": "hoq0NwA9lA_V"
      },
      "source": [
        "The goal of the second analysis task is to train linear regression models to predict users' ratings towards items. This involves a standard Data Science workflow: exploring data, building models, making predictions, and evaluating results. In this task, we will explore the impacts of feature selections and different sizes of training/testing data on the model performance. We will use another cleaned combined e-commerce sub-dataset that **is different from** the one in “Analysis of an E-commerce Dataset” task 1."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9fd3NU_lA_W",
      "metadata": {
        "id": "f9fd3NU_lA_W"
      },
      "source": [
        "### Import Cleaned E-commerce Dataset\n",
        "The csv file named 'cleaned_ecommerce_dataset.csv' is provided. You may need to use the Pandas method, i.e., `read_csv`, for reading it. After that, please print out its total length."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "PJrb2gtAlA_W",
      "metadata": {
        "id": "PJrb2gtAlA_W"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total length: 2685\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('cleaned_ecommerce_dataset.csv')\n",
        "total_length = len(df)\n",
        "\n",
        "# Print the total length\n",
        "print(\"Total length:\", total_length)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aqbuU6rglA_X",
      "metadata": {
        "id": "aqbuU6rglA_X"
      },
      "source": [
        "### Explore the Dataset\n",
        "\n",
        "* Use the methods, i.e., `head()` and `info()`, to have a rough picture about the data, e.g., how many columns, and the data types of each column.\n",
        "* As our goal is to predict ratings given other columns, please get the correlations between helpfulness/gender/category/review and rating by using the `corr()` method.\n",
        "* To get the correlations between different features, you may need to first convert the categorical features (i.e., gender, category and review) into numerial values. For doing this, you may need to import `OrdinalEncoder` from `sklearn.preprocessing` (refer to the useful exmaples [here](https://pbpython.com/categorical-encoding.html))\n",
        "* Please provide ___necessary explanations/analysis___ on the correlations, and figure out which are the ___most___ and ___least___ corrleated features regarding rating. Try to ___discuss___ how the correlation will affect the final prediction results, if we use these features to train a regression model for rating prediction. In what follows, we will conduct experiments to verify your hypothesis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "W3PImHiElA_X",
      "metadata": {
        "id": "W3PImHiElA_X"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset overview:\n",
            "   userId  timestamp                                           review  \\\n",
            "0    4081      71900                                Not always McCrap   \n",
            "1    4081      72000  I dropped the chalupa even before he told me to   \n",
            "2    4081      72000                     The Wonderful World of Wendy   \n",
            "3    4081     100399                             They actually did it   \n",
            "4    4081     100399                             Hey! Gimme some pie!   \n",
            "\n",
            "                                 item  rating  helpfulness gender  \\\n",
            "0                          McDonald's     4.0          3.0      M   \n",
            "1                           Taco Bell     1.0          4.0      M   \n",
            "2                             Wendy's     5.0          4.0      M   \n",
            "3  South Park: Bigger, Longer & Uncut     5.0          3.0      M   \n",
            "4                        American Pie     3.0          3.0      M   \n",
            "\n",
            "                category  item_id  item_price  user_city  \n",
            "0  Restaurants & Gourmet       41       30.74          4  \n",
            "1  Restaurants & Gourmet       74      108.30          4  \n",
            "2  Restaurants & Gourmet       84       69.00          4  \n",
            "3                 Movies       68      143.11          4  \n",
            "4                 Movies        6      117.89          4  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2685 entries, 0 to 2684\n",
            "Data columns (total 11 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   userId       2685 non-null   int64  \n",
            " 1   timestamp    2685 non-null   int64  \n",
            " 2   review       2685 non-null   object \n",
            " 3   item         2685 non-null   object \n",
            " 4   rating       2685 non-null   float64\n",
            " 5   helpfulness  2685 non-null   float64\n",
            " 6   gender       2685 non-null   object \n",
            " 7   category     2685 non-null   object \n",
            " 8   item_id      2685 non-null   int64  \n",
            " 9   item_price   2685 non-null   float64\n",
            " 10  user_city    2685 non-null   int64  \n",
            "dtypes: float64(3), int64(4), object(4)\n",
            "memory usage: 230.9+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OrdinalEncoder as OE\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('cleaned_ecommerce_dataset.csv')\n",
        "\n",
        "# Display dataset summary\n",
        "print(\"Dataset overview:\")\n",
        "print(df.head())\n",
        "print(df.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4myP5igslA_Y",
      "metadata": {
        "id": "4myP5igslA_Y"
      },
      "source": [
        "### Split Training and Testing Data\n",
        "* Machine learning models are trained to help make predictions for the future. Normally, we need to randomly split the dataset into training and testing sets, where we use the training set to train the model, and then leverage the well-trained model to make predictions on the testing set.\n",
        "* To further investigate whether the size of the training/testing data affects the model performance, please random split the data into training and testing sets with different sizes:\n",
        "    * Case 1: training data containing 10% of the entire data;\n",
        "    * Case 2: training data containing 90% of the entire data.\n",
        "* Print the shape of training and testing sets in the two cases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JIDMig9blA_Y",
      "metadata": {
        "id": "JIDMig9blA_Y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "DjSsgT0BlA_Y",
      "metadata": {
        "id": "DjSsgT0BlA_Y"
      },
      "source": [
        "### Train Linear Regression Models with Feature Selection under Cases 1 & 2\n",
        "* When training a machine learning model for prediction, we may need to select the most important/correlated input features for more accurate results.\n",
        "* To investigate whether feature selection affects the model performance, please select two most correlated features and two least correlated features regarding rating, respectively.\n",
        "* Train four linear regression models by following the conditions:\n",
        "    - (model-a) using the training/testing data in case 1 with two most correlated input features\n",
        "    - (model-b) using the training/testing data in case 1 with two least correlated input features\n",
        "    - (model-c) using the training/testing data in case 2 with two most correlated input features\n",
        "    - (model-d) using the training/testing data in case 2 with two least correlated input features\n",
        "* By doing this, we can verify the impacts of the size of traing/testing data on the model performance via comparing model-a and model-c (or model-b and model-d); meanwhile the impacts of feature selection can be validated via comparing model-a and model-b (or model-c and model-d).    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DASzPUATlA_Z",
      "metadata": {
        "id": "DASzPUATlA_Z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "KATSn7hYlA_Z",
      "metadata": {
        "id": "KATSn7hYlA_Z"
      },
      "source": [
        "### Evaluate Models\n",
        "* Evaluate the performance of the four models with two metrics, including MSE and Root MSE\n",
        "* Print the results of the four models regarding the two metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fU8GPS9lA_Z",
      "metadata": {
        "id": "4fU8GPS9lA_Z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "Y9jx-eY6lA_a",
      "metadata": {
        "id": "Y9jx-eY6lA_a"
      },
      "source": [
        "### Visualize, Compare and Analyze the Results\n",
        "* Visulize the results, and perform ___insightful analysis___ on the obtained results. For better visualization, you may need to carefully set the scale for the y-axis.\n",
        "* Normally, the model trained with most correlated features and more training data will get better results. Do you obtain the similar observations? If not, please ___explain the possible reasons___."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3TNAIGDilA_a",
      "metadata": {
        "id": "3TNAIGDilA_a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.11.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "03100797071d81d2fc1614d8d4a7b85db30280222e7da549502335b5750ba344"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
